{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNQwZH9UcwLtjOVhFgY9MzG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raykipa/Deep-Learning/blob/master/mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKY2_HjG0_pc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "5d75b568-be80-4cda-89ba-8e4ea86ae752"
      },
      "source": [
        "import tensorflow as tf\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train,y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QiyF8iw1Phf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
        "x_test= tf.keras.utils.normalize(x_test, axis=1)\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xe32z3y52sie",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "f593d676-59d4-4081-9cac-fbb33e9e3242"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=3)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 5s 88us/sample - loss: 0.2659 - acc: 0.9220\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.1110 - acc: 0.9656\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 5s 86us/sample - loss: 0.0757 - acc: 0.9764\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbe538cdbe0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mVVWrCr4Zdt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1828db23-6bc8-4940-c51d-2d60ef6ba03a"
      },
      "source": [
        "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
        "print(val_loss, val_acc)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 0s 42us/sample - loss: 0.1012 - acc: 0.9702\n",
            "0.10123127494864166 0.9702\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qv7zJCF-4zzY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('epic_num_reader.model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pSbSsow48O8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "bf16bc03-8535-4638-d4e0-cc7ee652056b"
      },
      "source": [
        "new_model=tf.keras.models.load_model('epic_num_reader.model')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZ0W_5Wt5jbo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "b542d40d-2eff-479f-ec7f-347266ed85aa"
      },
      "source": [
        "predictions = new_model.predict([x_test])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-872a9c2f0752>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m         callbacks=callbacks)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m   \u001b[0;31m# function we recompile the metrics based on the updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m   \u001b[0;31m# sample_weight_mode value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m   \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_execution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m   \u001b[0;31m# Prepare validation data. Hold references to the iterator and the input list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36m_make_execution_function\u001b[0;34m(model, mode)\u001b[0m\n\u001b[1;32m    564\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution_strategy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdistributed_training_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_execution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_execution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_make_execution_function\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   2187\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2189\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_predict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2190\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_make_predict_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2177\u001b[0m             \u001b[0mupdates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_updates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2178\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'predict_function'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2179\u001b[0;31m             **kwargs)\n\u001b[0m\u001b[1;32m   2180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2181\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_make_execution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, updates, name, **kwargs)\u001b[0m\n\u001b[1;32m   3676\u001b[0m                'backend') % key\n\u001b[1;32m   3677\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3678\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mGraphExecutionFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, updates, name, **session_kwargs)\u001b[0m\n\u001b[1;32m   3328\u001b[0m     \u001b[0;31m# dependencies in call.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3329\u001b[0m     \u001b[0;31m# Index 0 = total loss or model output for `predict`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3330\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3331\u001b[0m       \u001b[0mupdates_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3332\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mupdate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCHfYqjc5jNJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k95NSVKI17a-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "23e0c850-91bd-489e-800e-21610b2815c7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(x_train[0], cmap= plt.cm.binary)\n",
        "plt.show()\n",
        "print(x_train[0])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.00393124 0.02332955 0.02620568 0.02625207 0.17420356 0.17566281\n",
            "  0.28629534 0.05664824 0.51877786 0.71632322 0.77892406 0.89301644\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.05780486 0.06524513 0.16128198 0.22713296\n",
            "  0.22277047 0.32790981 0.36833534 0.3689874  0.34978968 0.32678448\n",
            "  0.368094   0.3747499  0.79066747 0.67980478 0.61494005 0.45002403\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.12250613 0.45858525 0.45852825 0.43408872 0.37314701\n",
            "  0.33153488 0.32790981 0.36833534 0.3689874  0.34978968 0.32420121\n",
            "  0.15214552 0.17865984 0.25626376 0.1573102  0.12298801 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.04500225 0.4219755  0.45852825 0.43408872 0.37314701\n",
            "  0.33153488 0.32790981 0.28826244 0.26543758 0.34149427 0.31128482\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.1541463  0.28272888 0.18358693 0.37314701\n",
            "  0.33153488 0.26569767 0.01601458 0.         0.05945042 0.19891229\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.0253731  0.00171577 0.22713296\n",
            "  0.33153488 0.11664776 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.20500962\n",
            "  0.33153488 0.24625638 0.00291174 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.01622378\n",
            "  0.24897876 0.32790981 0.10191096 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.04586451 0.31235677 0.32757096 0.23335172 0.14931733 0.00129164\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.10498298 0.34940902 0.3689874  0.34978968 0.15370495\n",
            "  0.04089933 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.06551419 0.27127137 0.34978968 0.32678448\n",
            "  0.245396   0.05882702 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.02333517 0.12857881 0.32549285\n",
            "  0.41390126 0.40743158 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.32161793\n",
            "  0.41390126 0.54251585 0.20001074 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.06697006 0.18959827 0.25300993 0.32678448\n",
            "  0.41390126 0.45100715 0.00625034 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.05110617 0.19182076 0.33339444 0.3689874  0.34978968 0.32678448\n",
            "  0.40899334 0.39653769 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.04117838 0.16813739\n",
            "  0.28960162 0.32790981 0.36833534 0.3689874  0.34978968 0.25961929\n",
            "  0.12760592 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.04431706 0.11961607 0.36545809 0.37314701\n",
            "  0.33153488 0.32790981 0.36833534 0.28877275 0.111988   0.00258328\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.05298497 0.42752138 0.4219755  0.45852825 0.43408872 0.37314701\n",
            "  0.33153488 0.25273681 0.11646967 0.01312603 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.37491383 0.56222061\n",
            "  0.66525569 0.63253163 0.48748768 0.45852825 0.43408872 0.359873\n",
            "  0.17428513 0.01425695 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.92705966 0.82698729\n",
            "  0.74473314 0.63253163 0.4084877  0.24466922 0.22648107 0.02359823\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h96XPx972RI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}